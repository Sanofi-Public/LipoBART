{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fad9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "with open(\"../data/ding_et_al/split.json\") as f:\n",
    "    split_df = json.load(f)\n",
    "data_path = \"../data/ding_et_al/all_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bf0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GCN setup and methods ---\n",
    "def train(model, train_data, val_data, epochs, patience):\n",
    "    val_epochs = []\n",
    "    val_scores = []\n",
    "    train_scores = []\n",
    "    best_val_score = float(\"inf\")\n",
    "    stop_epoch = epochs\n",
    "    print(\"Training GCN...\")\n",
    "    for i in range(epochs):\n",
    "        model.fit(train_data, nb_epoch=1, checkpoint_interval=0)\n",
    "        train_pred = model.predict(train_data).squeeze()[:, 1]\n",
    "        train_scores.append(log_loss(train_data.y, train_pred))\n",
    "        val_pred = model.predict(val_data).squeeze()[:, 1]\n",
    "        val_scores.append(log_loss(val_data.y, val_pred))\n",
    "\n",
    "        # ----- Early Stopping -----\n",
    "        if i > patience and min(val_scores[-patience:]) > best_val_score:\n",
    "            print(f\"Early stopping after {i - patience} epochs\")\n",
    "            stop_epoch = i - patience\n",
    "            model.restore()\n",
    "            break\n",
    "\n",
    "        if val_scores[-1] < best_val_score and i > 100:\n",
    "            best_val_score = val_scores[-1]\n",
    "            model.save_checkpoint()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"epoch: {i}, train_loss {train_scores[-1]}, val_loss {val_scores[-1]}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- load data ---\n",
    "df = pd.read_csv(data_path)\n",
    "smiles = df[\"m1\"].values\n",
    "featurizer = dc.feat.MolGraphConvFeaturizer()\n",
    "loader = dc.data.InMemoryLoader(tasks=[\"y2\"], featurizer=featurizer)\n",
    "dataset = loader.create_dataset(list(zip(smiles, df[\"y2\"].values)))\n",
    "dc_dataset_train = dataset.select(split_df[\"train\"])\n",
    "dc_dataset_val = dataset.select(split_df[\"val\"])\n",
    "dc_dataset_test = dataset.select(split_df[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setup GCN --- #\n",
    "hyperparams = {\n",
    "    \"batch_size\": 64,\n",
    "    \"dense_layer_size\": 32,\n",
    "    \"graph_conv_layers\": [32, 32],\n",
    "    \"dropout\": [0.3, 0.3, 0.3],\n",
    "    \"learning_rate\": 0.005,\n",
    "}\n",
    "epochs = 5000\n",
    "patience = 500\n",
    "dc_model = dc.models.GraphConvModel(1, mode=\"classification\", batch_normalize=True, **hyperparams)\n",
    "\n",
    "# --- Train and Evaluate GCN --- #\n",
    "dc_model = train(dc_model, dc_dataset_train, dc_dataset_val, epochs, patience)\n",
    "probs = dc_model.predict(dc_dataset_test).squeeze()[:, 1]\n",
    "val_probs = dc_model.predict(dc_dataset_val).squeeze()[:, 1]\n",
    "labels_val = dc_dataset_val.y\n",
    "labels_test = dc_dataset_test.y\n",
    "print(f\"Val AUC (GCN): {roc_auc_score(labels_val, val_probs)}\")\n",
    "print(f\"Test AUC (GCN): {roc_auc_score(labels_test, probs)}\")\n",
    "test_preds = probs > 0.5\n",
    "val_preds = val_probs > 0.5\n",
    "print(f\"Val Accuracy (GCN): {balanced_accuracy_score(labels_val, val_preds)}\")\n",
    "print(f\"Test Accuracy (GCN): {balanced_accuracy_score(labels_test, test_preds)}\")\n",
    "print(f\"Val F1 (GCN): {f1_score(labels_val, val_preds)}\")\n",
    "print(f\"Test F1 (GCN): {f1_score(labels_test, test_preds)}\")\n",
    "print(f\"Val MCC (GCN): {matthews_corrcoef(labels_val, val_preds)}\")\n",
    "print(f\"Test MCC (GCN): {matthews_corrcoef(labels_test, test_preds)}\")\n",
    "\n",
    "# Make a dictionary that maps SMILES strings to their corresponding embeddings\n",
    "gcn_X = dc_model.predict_embedding(dataset)[: len(dataset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f263d7-574f-4614-b697-ae898024bb71",
   "metadata": {},
   "source": [
    "Save GCN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f89afc-ede5-49f2-b335-742f950df77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gcn_x.npy\", \"wb\") as f:\n",
    "    np.save(f, gcn_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc0968-c62f-4fa6-b7db-af3557a02156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lnp",
   "language": "python",
   "name": "lnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "2cb424124a72f34ff51dcdc06273546de873365fee37dc5a1ddc2de1ace99d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
