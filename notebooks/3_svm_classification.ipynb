{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3335e0cf-081f-4a46-b752-c5808e26caa8",
   "metadata": {},
   "source": [
    "# Train and Test a XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0dae64-259b-461e-84ec-4df565f0579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634577ab-7f23-4422-b908-37d83e6d10fc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b7f62-9fb3-4069-bca7-0387bf425e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.to_dict(orient=\"records\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848d970-f341-45ce-a030-fc1f1ee490c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "lnps = load_data(\"../data/ding_et_al/all_data.csv\")\n",
    "with open(\"../data/ding_et_al/split.json\") as f:\n",
    "    split_df = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeed57a-1c93-4161-9559-8fdecca863cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- This function we use for 'our' methods ---\n",
    "# we simply generate a feature matrix using only the embeddings from the m1 molecule\n",
    "def generate_simple_feature_matrix(data_df, fp_dict):\n",
    "    X = []\n",
    "    y = []\n",
    "    processed_data = []\n",
    "    for item in data_df:\n",
    "        result = {}\n",
    "        result[\"label\"] = item[\"y2\"]\n",
    "        result[\"m1_fingerprint\"] = fp_dict[item[\"m1\"]]\n",
    "        processed_data.append(result)\n",
    "        X_item = result[\"m1_fingerprint\"]\n",
    "        X.append(X_item)\n",
    "        y.append(item[\"y2\"])\n",
    "    return (X, y, processed_data)\n",
    "\n",
    "\n",
    "# -- Functions from Ding et al. to process data --\n",
    "def convert_to_one_hot(val, min, max, step):\n",
    "    result = []\n",
    "    for i in range(int((max - min) / step)):\n",
    "        if i * step <= val < (i + 1) * step:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_feature_matrix(data_df, fp_dict):\n",
    "    X = []\n",
    "    y = []\n",
    "    processed_data = []\n",
    "\n",
    "    for item in data_df:\n",
    "        result = {}\n",
    "        result[\"label\"] = item[\"y2\"]\n",
    "        result[\"p1_feature\"] = convert_to_one_hot(item[\"p1\"], min=0, max=100, step=5)\n",
    "        result[\"p2_feature\"] = convert_to_one_hot(item[\"p2\"], min=0, max=100, step=5)\n",
    "        result[\"p3_feature\"] = convert_to_one_hot(item[\"p3\"], min=0, max=100, step=5)\n",
    "        result[\"p4_feature\"] = convert_to_one_hot(item[\"p4\"], min=0, max=1.5, step=0.25)\n",
    "        result[\"m1_fingerprint\"] = fp_dict[item[\"m1\"]]\n",
    "        result[\"m2_fingerprint\"] = fp_dict[item[\"m2\"]]\n",
    "        result[\"m3_fingerprint\"] = fp_dict[item[\"m3\"]]\n",
    "        result[\"m4_fingerprint\"] = fp_dict[item[\"m4\"]]\n",
    "\n",
    "        processed_data.append(result)\n",
    "        X_item = (\n",
    "            result[\"p1_feature\"]\n",
    "            + result[\"p2_feature\"]\n",
    "            + result[\"p3_feature\"]\n",
    "            + result[\"p4_feature\"]\n",
    "            + result[\"m1_fingerprint\"]\n",
    "            + result[\"m2_fingerprint\"]\n",
    "            + result[\"m3_fingerprint\"]\n",
    "            + result[\"m4_fingerprint\"]\n",
    "        )\n",
    "        X.append(X_item)\n",
    "        y.append(item[\"y2\"])\n",
    "    return (X, y, processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb17889-1695-4880-aef8-e304a5f6dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in fingerprints --- #\n",
    "with open(\"../data/ding_et_al/mol2fp_grover_large.json\", \"r\") as f:\n",
    "    df_fp_grover_large = json.load(f)\n",
    "with open(\"../data/ding_et_al/mol2fp_grover.json\", \"r\") as f:\n",
    "    df_fp_grover = json.load(f)\n",
    "with open(\"../data/ding_et_al/mol2fp.json\", \"r\") as f:\n",
    "    df_fp = json.load(f)\n",
    "with open(\"../data/mol2fp_cfp_all_data.json\", \"r\") as f:\n",
    "    df_fp_cfp = json.load(f)\n",
    "with open(\"../data/mol2fp_MegaMB_base_all_data.json\", \"r\") as f:\n",
    "    df_fp_mmb = json.load(f)\n",
    "with open(\"../data/mol2fp_MegaMB_finetuned_all_data.json\", \"r\") as f:\n",
    "    df_fp_mmb_ft = json.load(f)\n",
    "gcn_X = np.load(\"../data/gcn_x.npy\")\n",
    "\n",
    "fp_X, y, _ = generate_feature_matrix(lnps, df_fp)\n",
    "grover_X, _, _ = generate_feature_matrix(lnps, df_fp_grover)\n",
    "grover_large_X, _, _ = generate_feature_matrix(lnps, df_fp_grover_large)\n",
    "cfp_X, _, _ = generate_simple_feature_matrix(lnps, df_fp_cfp)\n",
    "mmb_X, _, _ = generate_simple_feature_matrix(lnps, df_fp_mmb)\n",
    "mmb_ft_X, _, _ = generate_simple_feature_matrix(lnps, df_fp_mmb_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269bfe3-2ece-4acc-b8f8-6a16dfdcc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Make Hybrid fingerprints ----\n",
    "fp_grover_X = pd.concat([pd.DataFrame(fp_X), pd.DataFrame(grover_X)], axis=1)\n",
    "fp_grover_large_X = pd.concat([pd.DataFrame(fp_X), pd.DataFrame(grover_large_X)], axis=1)\n",
    "cfp_mmb_ft_X = pd.concat([pd.DataFrame(cfp_X), pd.DataFrame(mmb_ft_X)], axis=1)\n",
    "gcn_cfp_X = pd.concat([pd.DataFrame(gcn_X), pd.DataFrame(cfp_X)], axis=1)\n",
    "gcn_mmb_ft_X = pd.concat([pd.DataFrame(gcn_X), pd.DataFrame(mmb_ft_X)], axis=1)\n",
    "gcn_mmb_ft_cfp = pd.concat(\n",
    "    [pd.DataFrame(gcn_X), pd.DataFrame(mmb_ft_X), pd.DataFrame(cfp_X)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbecee7",
   "metadata": {},
   "source": [
    "## Train and test SVM\n",
    "> Use different embeddings for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab56536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_svm(X, y, split_df, param_c):\n",
    "    X_train = np.array(X)[split_df[\"train\"],]\n",
    "    X_val = np.array(X)[split_df[\"val\"],]\n",
    "    X_test = np.array(X)[split_df[\"test\"],]\n",
    "    y_train = np.array(y)[split_df[\"train\"]]\n",
    "    y_val = np.array(y)[split_df[\"val\"]]\n",
    "    y_test = np.array(y)[split_df[\"test\"]]\n",
    "\n",
    "    val_auc = []\n",
    "    test_auc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "    val_f1 = []\n",
    "    test_f1 = []\n",
    "    val_mcc = []\n",
    "    test_mcc = []\n",
    "    for c in param_c:\n",
    "        svc = svm.SVC(kernel=\"linear\", C=c)\n",
    "        svc.fit(X_train, y_train)\n",
    "        clf_prob_val = svc.decision_function(X_val)\n",
    "        clf_prob_test = svc.decision_function(X_test)\n",
    "        val_auc.append(roc_auc_score(y_val, clf_prob_val))\n",
    "        test_auc.append(roc_auc_score(y_test, clf_prob_test))\n",
    "        pred_val = svc.predict(X_val)\n",
    "        pred_test = svc.predict(X_test)\n",
    "        val_acc.append(balanced_accuracy_score(y_val, pred_val))\n",
    "        test_acc.append(balanced_accuracy_score(y_test, pred_test))\n",
    "        val_f1.append(f1_score(y_val, pred_val))\n",
    "        test_f1.append(f1_score(y_test, pred_test))\n",
    "        val_mcc.append(matthews_corrcoef(y_val, pred_val))\n",
    "        test_mcc.append(matthews_corrcoef(y_test, pred_test))\n",
    "    return (val_auc, test_auc, val_acc, test_acc, val_f1, test_f1, val_mcc, test_mcc)\n",
    "\n",
    "\n",
    "def run_svm(X, y, split_df, param_c):\n",
    "    val_auc, test_auc, val_acc, test_acc, val_f1, test_f1, val_mcc, test_mcc = select_svm(\n",
    "        X, y, split_df, param_c\n",
    "    )\n",
    "    best_idx = np.argmax(val_auc)\n",
    "    print(\"VAL\")\n",
    "    print(f\"AUC: {val_auc[best_idx]}\")\n",
    "    print(f\"Balanced Accuracy: {val_acc[best_idx]}\")\n",
    "    print(f\"F1: {val_f1[best_idx]}\")\n",
    "    print(f\"MCC: {val_mcc[best_idx]}\")\n",
    "    print(\"TEST\")\n",
    "    # print(test_auc_svm)\n",
    "    print(f\"AUC: {test_auc[best_idx]}\")\n",
    "    print(f\"Balanced Accuracy: {test_acc[best_idx]}\")\n",
    "    print(f\"F1: {test_f1[best_idx]}\")\n",
    "    print(f\"MCC: {test_mcc[best_idx]}\")\n",
    "    # Latex table row\n",
    "    print(\n",
    "        f\"{val_auc[best_idx]:.3f} & {test_auc[best_idx]:.3f} & {val_acc[best_idx]:.3f} & {test_acc[best_idx]:.3f} & {val_f1[best_idx]:.3f} & {test_f1[best_idx]:.3f} & {val_mcc[best_idx]:.3f} & {test_mcc[best_idx]:.3f} \\\\\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b044a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expert --- #\n",
    "run_svm(fp_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee120eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grover --- #\n",
    "run_svm(grover_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grover-Large --- #\n",
    "run_svm(grover_large_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4de789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expert-Grover --- #\n",
    "run_svm(fp_grover_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expert-Grover-Large --- #\n",
    "run_svm(fp_grover_large_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c139f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CFP --- #\n",
    "run_svm(cfp_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MegaMolBART base --- #\n",
    "run_svm(mmb_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MegaMolBART Fine-tuned --- #\n",
    "run_svm(mmb_ft_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MegaMolBART Fine-tuned CFP --- #\n",
    "run_svm(cfp_mmb_ft_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GCN --- #\n",
    "run_svm(gcn_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GCN-CFP --- #\n",
    "run_svm(gcn_cfp_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47948f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GCN-MMB Fine-tuned --- #\n",
    "run_svm(gcn_mmb_ft_X, y, split_df, c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62436f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GCN-MMB Fine-tuned-CFP --- #\n",
    "run_svm(gcn_mmb_ft_cfp, y, split_df, c_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lnp",
   "language": "python",
   "name": "lnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "2cb424124a72f34ff51dcdc06273546de873365fee37dc5a1ddc2de1ace99d5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
